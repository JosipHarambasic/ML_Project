{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_project_notebook (2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosipHarambasic/ML_Project/blob/master/ml_project_notebook_new2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H2YSwnoPX6y",
        "outputId": "620320c8-4ae9-443a-c0af-c72dd84d2bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML_Project'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 112 (delta 44), reused 91 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (112/112), 44.09 MiB | 12.15 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "xhX8N-rzP9Rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install verstack\n",
        "!pip install catboost\n",
        "!pip install pyod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NNoo1k3ZmBBO",
        "outputId": "936274ac-0094-40cf-d08f-9f5d94e83a7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting verstack\n",
            "  Downloading verstack-3.0.3.tar.gz (9.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.6 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from verstack) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from verstack) (1.21.5)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from verstack) (0.90)\n",
            "Collecting scikit-learn==1.0.1\n",
            "  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting lightgbm==3.3.0\n",
            "  Downloading lightgbm-3.3.0-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 32.7 MB/s \n",
            "\u001b[?25hCollecting optuna==2.10.0\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 48.9 MB/s \n",
            "\u001b[?25hCollecting plotly==5.3.1\n",
            "  Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from verstack) (3.2.2)\n",
            "Collecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 36.2 MB/s \n",
            "\u001b[?25hCollecting holidays==0.11.3.1\n",
            "  Downloading holidays-0.11.3.1-py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (from verstack) (0.14.0)\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 24 kB/s \n",
            "\u001b[?25hCollecting keras==2.7.0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 38.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays==0.11.3.1->verstack) (2.2.3)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays==0.11.3.1->verstack) (0.2.1)\n",
            "Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays==0.11.3.1->verstack) (2.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.3.0->verstack) (0.37.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.3.0->verstack) (1.4.1)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.10.0->verstack) (1.4.32)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna==2.10.0->verstack) (4.63.0)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna==2.10.0->verstack) (3.13)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.10.0->verstack) (21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly==5.3.1->verstack) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly==5.3.1->verstack) (8.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1->verstack) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1->verstack) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.44.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (0.24.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (3.17.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (13.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (1.14.0)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (3.1.0)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0->verstack) (2.0)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays==0.11.3.1->verstack) (0.5.11)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0->verstack) (1.5.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna==2.10.0->verstack) (3.0.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.10.0->verstack) (4.11.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.10.0->verstack) (1.1.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0->verstack) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->verstack) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->verstack) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->verstack) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->verstack) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna==2.10.0->verstack) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0->verstack) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->verstack) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->verstack) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->verstack) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0->verstack) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0->verstack) (3.2.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.10.0->verstack) (5.4.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 44.3 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 37.3 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.10.0->verstack) (3.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.10.0->verstack) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.10.0->verstack) (21.4.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna==2.10.0->verstack) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->verstack) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->verstack) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->verstack) (2018.9)\n",
            "Building wheels for collected packages: verstack, pyperclip\n",
            "  Building wheel for verstack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for verstack: filename=verstack-3.0.3-py3-none-any.whl size=73100 sha256=aa9491b575fb9a250a9d3a463f700c6661fdd9ebf892e59e39efd5b7381f0374\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/7d/41/2b9ac43b55213e71352931fc34878f7dd9d10b887555a625f7\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=ee5c9cb8fb8a4e4f11889a1b75c0734301d4fb68476e2b546b1d7c5388feeab4\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built verstack pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, python-dateutil, Mako, cmd2, autopage, tensorflow-estimator, scikit-learn, keras, gast, colorlog, cmaes, cliff, alembic, tensorflow, plotly, optuna, lightgbm, holidays, verstack\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.5.0\n",
            "    Uninstalling plotly-5.5.0:\n",
            "      Successfully uninstalled plotly-5.5.0\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: holidays\n",
            "    Found existing installation: holidays 0.10.5.2\n",
            "    Uninstalling holidays-0.10.5.2:\n",
            "      Successfully uninstalled holidays-0.10.5.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 gast-0.4.0 holidays-0.11.3.1 keras-2.7.0 lightgbm-3.3.0 optuna-2.10.0 pbr-5.8.1 plotly-5.3.1 pyperclip-1.8.2 python-dateutil-2.8.1 scikit-learn-1.0.1 stevedore-3.5.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 verstack-3.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.5-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (3.10.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.5\n",
            "Collecting pyod\n",
            "  Downloading pyod-0.9.9.tar.gz (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyod) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.21.5)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.4.1)\n",
            "Requirement already satisfied: scikit_learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyod) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod) (0.10.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (57.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>=0.20.0->pyod) (3.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->pyod) (3.10.0.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (0.5.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels->pyod) (2018.9)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.9.9-py3-none-any.whl size=139325 sha256=b75e02500cea37b90ff84756774e4d83371eb502ac4d65a8e85355585267c049\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/32/f0/0dc3050775e77b6661a116b70817b02b4305fa253269d6d998\n",
            "Successfully built pyod\n",
            "Installing collected packages: pyod\n",
            "Successfully installed pyod-0.9.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "from scipy import stats\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "from verstack import NaNImputer\n",
        "from pyod.models.iforest import IForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import StackingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "MPJ1fGs7Qhgy",
        "pycharm": {
          "is_executing": true
        }
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # do not show warnings"
      ],
      "metadata": {
        "id": "oo0QnAcQjjZG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpers"
      ],
      "metadata": {
        "id": "xpuGNAJSP_Br"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model related"
      ],
      "metadata": {
        "id": "O1oIE84yslGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_vanilla(X_train, y_train, X_test, y_test):\n",
        "    ETC = ExtraTreesClassifier(random_state=42, n_jobs=-1)\n",
        "    RFC = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    GBC = GradientBoostingClassifier(random_state=42)\n",
        "    LGBMC = LGBMClassifier(random_state=42, n_jobs=-1)\n",
        "    XGBC = XGBClassifier(seed=42)\n",
        "    CBC = CatBoostClassifier(random_state=42, verbose=0)\n",
        "    KNN = KNeighborsClassifier(n_jobs=-1)\n",
        "    SGDC = SGDClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "    names = ['ETC', 'RFC', 'GBC', 'LGBMC', 'XGBC', 'CBC', 'KNN', 'SGDC']\n",
        "    models = [ETC, RFC, GBC, LGBMC, XGBC, CBC, KNN, SGDC]\n",
        "    hyperparameter_ETC = dict(n_estimators=list(range(100,250,10)),\n",
        "                              criterion=[\"gini\",\"entropy\"],\n",
        "                              max_features=[\"auto\", \"sqrt\", \"log2\"],\n",
        "                              class_weight=[\"balanced\", \"balanced_subsample\"],\n",
        "                              verbose=[0,1,2],\n",
        "                              ccp_alpha=[0,0.1,0.01])\n",
        "    hyperparameter_RFC = dict(n_estimators = [5, 20, 50, 100, 150, 200], \n",
        "                              max_features = ['auto', 'sqrt'],\n",
        "                              max_depth = [int(x) for x in np.linspace(10, 120, num = 12)],\n",
        "                              min_samples_split = [2, 6, 10], \n",
        "                              min_samples_leaf = [1, 3, 4, 5, 7],\n",
        "                              bootstrap = [True, False])\n",
        "                            \n",
        "    hyperparameter_KNN = dict(leaf_size=list(range(5,20)), n_neighbors=list(range(5,20)), p=[1,2])\n",
        "\n",
        "    for name, model in zip(names, models):\n",
        "        metric = 'Accuracy'\n",
        "        cv = RepeatedKFold(n_splits=5, \n",
        "                          n_repeats=1, \n",
        "                          random_state=42)\n",
        "        if name == \"ETC\":\n",
        "          grid = GridSearchCV(estimator=model, \n",
        "                              param_grid=hyperparameter_ETC, \n",
        "                              scoring=metric.lower(),\n",
        "                              cv=cv, \n",
        "                              verbose=0,\n",
        "                              n_jobs=-1)\n",
        "        else:\n",
        "          grid = GridSearchCV(estimator=model, \n",
        "                              param_grid={}, \n",
        "                              scoring=metric.lower(),\n",
        "                              cv=cv, \n",
        "                              verbose=0,\n",
        "                              n_jobs=-1)\n",
        "        grid.fit(X_train, y_train)\n",
        "        print(f\"{metric} for {name}: {grid.score(X_test, y_test)}\")"
      ],
      "metadata": {
        "id": "HSc-4dDxsnuV"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_importances(X, \n",
        "                            y, \n",
        "                            max_features: int) -> dict:\n",
        "    ETC = ExtraTreesClassifier(random_state=42, n_jobs=-1)\n",
        "    RFC = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    GBC = GradientBoostingClassifier(random_state=42)\n",
        "    LGBMC = LGBMClassifier(random_state=42, n_jobs=-1)\n",
        "    XGBC = XGBClassifier(seed=42)\n",
        "    CBC = CatBoostClassifier(random_state=42, verbose=0)\n",
        "    SGDC = SGDClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "    names = ['ETC', 'RFC', 'GBC', 'LGBMC', 'XGBC', 'CBC', 'SGDC']\n",
        "    models = [ETC, RFC, GBC, LGBMC, XGBC, CBC, SGDC]\n",
        "\n",
        "    feature_importances_0 = np.zeros((7, max_features))\n",
        "    feature_importances_1 = np.zeros((7, max_features//2))\n",
        "    feature_importances_2 = np.zeros((7, max_features//4))\n",
        "    \n",
        "    for i, name, model in zip(range(len(models)), names, models):\n",
        "        print(f'Fitting {name}...', end=' ')\n",
        "        model.fit(X, y)\n",
        "        print('Done')\n",
        "        selector_0 = SelectFromModel(model, \n",
        "                                     threshold=-np.inf,\n",
        "                                     prefit=True,\n",
        "                                     max_features=max_features)\n",
        "        feature_importances_0[i] = selector_0.get_support(indices=True)\n",
        "\n",
        "        selector_1 = SelectFromModel(model, \n",
        "                                     threshold=-np.inf,\n",
        "                                     prefit=True,\n",
        "                                     max_features=max_features//2)\n",
        "        feature_importances_1[i] = selector_1.get_support(indices=True)\n",
        "\n",
        "        selector_2 = SelectFromModel(model, \n",
        "                                     threshold=-np.inf,\n",
        "                                     prefit=True,\n",
        "                                     max_features=max_features//4)\n",
        "        feature_importances_2[i] = selector_2.get_support(indices=True)\n",
        "\n",
        "    tfi_0 = feature_importances_0.flatten()\n",
        "    tfi_1 = feature_importances_1.flatten()\n",
        "    tfi_2 = feature_importances_2.flatten()\n",
        "\n",
        "    u_0 = np.unique(tfi_0)\n",
        "    u_1 = np.unique(tfi_1)\n",
        "    u_2 = np.unique(tfi_2)\n",
        "\n",
        "    fi_dict = {f'feature_importances_{max_features}': u_0.astype(int),\n",
        "               f'feature_importances_{max_features//2}': u_1.astype(int),\n",
        "               f'feature_importances_{max_features//4}': u_2.astype(int)}\n",
        "\n",
        "    return fi_dict"
      ],
      "metadata": {
        "id": "kt2K5JTOmaT9"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset class"
      ],
      "metadata": {
        "id": "Mt0E-hfuJK0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataSet:\n",
        "    \"\"\"\n",
        "    Class handling all preprocessing with different possible configurations\n",
        "\n",
        "    :param path: Path to datasets\n",
        "    :param years: List of years to be considered\n",
        "    :param nan_handler: List of NaN handling methods - Options: 'threshold', empty\n",
        "    :param zero_handler: List of zero handling methods - Options: 'threshold', 'replace', 'drop_again', empty\n",
        "                         - Is stackable, but 'drop_again' needs the 'replace' argument - e.g. ['replace', 'drop_again']\n",
        "    :param imputation_handler: Imputation method - Options: 'mean', 'KNN', 'XGB'\n",
        "    :param outlier_handler: List of outlier handling methods - Options: 'quantile', 'IForest'\n",
        "                            - Is stackable - e.g. ['quantile', 'IForest']\n",
        "    :param config_dict: Dictionary that defines the thresholds and contamination (for IForest) for each year.\n",
        "                        It has to be structured the following way:\n",
        "\n",
        "                                      config_dict = {\n",
        "                                                      2014: {\n",
        "                                                          'nans_thres': float (e.g. 0.08), \n",
        "                                                          'zeros_thres': float (e.g. 0.08),\n",
        "                                                          'cut_lower': float (e.g. 0.01),\n",
        "                                                          'cut_upper': float (e.g. 0.99),\n",
        "                                                          'IForest_contamination': float (e.g. 0.02)\n",
        "                                                      },\n",
        "                                                    ...\n",
        "                                                    }\n",
        "                        :key nans_thres: Sets the NaN threshold, such that columns that surpass this threshold\n",
        "                                         are removed (e.g. 0.08 - allowing up to 8% NaNs in columns)\n",
        "                        :key zeros_thres: Sets zero threshold, such that columns that surpass this threshold\n",
        "                                          are removed (e.g. 0.08 - allowing up to 8% zeros in columns)\n",
        "                        :key cut_lower: Sets lower bound, such that rows that have a price var which falls below \n",
        "                                        the quantile are removed (e.g. 0.01)\n",
        "                        :key cut_upper: Sets upper bound, such that rows that have a price var which is above \n",
        "                                        the quantile are removed (e.g. 0.01)\n",
        "                        : key IForest_contamination: Sets the contamination percentage of the dataset (e.g 0.02 - 2% outliers)\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 path: str = '',\n",
        "                 benchmark = 2.5,\n",
        "                 counter = 0,\n",
        "                 sp_index: list = [-0.73, 9.54, 19.42, -6.24, 28.88],\n",
        "                 years: list = [2014, 2015, 2016, 2017, 2018],\n",
        "                 nan_handler: list = ['threshold'],\n",
        "                 zero_handler: list = ['threshold', 'replace'],\n",
        "                 imputation_handler: str = 'XGB',\n",
        "                 outlier_handler: list = ['quantile', 'IForest'],\n",
        "                 config_dict: dict = {}\n",
        "                 ):\n",
        "        self.path = path\n",
        "        self.years = years\n",
        "        self.nan_handler = nan_handler\n",
        "        self.zero_handler = zero_handler\n",
        "        self.imputation_handler = imputation_handler\n",
        "        self.outlier_handler = outlier_handler\n",
        "        self.config_dict = config_dict\n",
        "        self.sp_index = sp_index\n",
        "        self.benchmark = benchmark\n",
        "        self.counter = counter\n",
        "\n",
        "        self.df = None\n",
        "        self.year = None\n",
        "        self.init_shape = None\n",
        "        self.class_col = None\n",
        "        self.sector_col = None\n",
        "        self.sector_ids = None\n",
        "        self.sector_mapper = None\n",
        "        self.dfs = []\n",
        "        self.intersec_cols = None\n",
        "\n",
        "    def create_dataset(self):\n",
        "        \"\"\"\n",
        "        Creates the whole dataset:\n",
        "            - Stores dataframe per year in self.dfs\n",
        "            - Finds intersecting columns between all dataframes\n",
        "            - Concatenates all dataframes with the selected columns\n",
        "            - Factorize the 'Sector' column -> Assign ID to each string\n",
        "            - Rename feature names to avoid UTF-8 encoding issues with LGBM\n",
        "        \"\"\"\n",
        "\n",
        "        # loop over all years\n",
        "        for year in self.years:\n",
        "            self.__print_sep(60, '#', '\\n')\n",
        "\n",
        "            # generate single dataframe\n",
        "            self.prepare_single_dataframe(year)\n",
        "\n",
        "            # append dataframe\n",
        "            self.dfs.append(self.df)\n",
        "            self.counter += 1\n",
        "\n",
        "        # print seperators\n",
        "        self.__print_sep(60, '#')\n",
        "        self.__print_sep(60, '#', '\\n')\n",
        "\n",
        "        # get intersecting columns\n",
        "        self.get_intersecting_columns()\n",
        "\n",
        "        # concatenate dataframes to one\n",
        "        df = self.concat_intersecting_dfs()\n",
        "\n",
        "        # factorize 'Sector' column\n",
        "        df = self.factorize_col(df)\n",
        "\n",
        "        # avoid encoding issues with feature names\n",
        "        df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
        "\n",
        "        return df\n",
        "\n",
        "    def prepare_single_dataframe(self, year: int):\n",
        "        \"\"\"\n",
        "        Prepares a dataframe for a specific year\n",
        "\n",
        "        :param year: Sets year\n",
        "\n",
        "            - Loads data into dataframe\n",
        "            - Drop the 'Class' column for preprocessing\n",
        "            - Preprocess NaNs\n",
        "            - Preprocess zeros\n",
        "            - Factorize 'Sector' column for imputation\n",
        "            - Impute NaNs\n",
        "            - Detect and remove outliers\n",
        "            - Scale data\n",
        "            - Convert data to float32 and join back 'Class' column\n",
        "            - Map back the 'Sector' column\n",
        "        \"\"\"\n",
        "        # load data\n",
        "        self.load_df(year)\n",
        "\n",
        "        # store and drop 'Class' column\n",
        "        self.store_drop_class_col()\n",
        "\n",
        "        # handle NaNs\n",
        "        self.handle_nans()\n",
        "\n",
        "        # handle zeros\n",
        "        self.handle_zeros()\n",
        "\n",
        "        # factorize 'Sector' column and store its mapper\n",
        "        self.store_factorize_sector_col()\n",
        "\n",
        "        # impute NaNs\n",
        "        self.impute_nans()\n",
        "\n",
        "        # handle outliers\n",
        "        self.handle_outliers()\n",
        "\n",
        "        # drop VAR column\n",
        "        self.drop_var_col()\n",
        "\n",
        "        # scale data\n",
        "        self.scale_data()\n",
        "\n",
        "        # convert to float 32 and join\n",
        "        self.convert_join()\n",
        "\n",
        "        # map 'Sector' back to string representation\n",
        "        self.map_sector_inv()\n",
        "\n",
        "    def load_df(self, year: int):\n",
        "        self.__print_header(f'LOADING {year}')\n",
        "        self.year = year\n",
        "        print(f'Loading {year}_Financial_Data.csv into a DataFrame', end=' - ')\n",
        "        self.df = pd.read_csv(f'/content/{year}_Financial_Data.csv',\n",
        "                              index_col=0)\n",
        "        print('COMPLETE')\n",
        "        self.init_shape = self.df.shape\n",
        "        buy = self.sp_index[self.counter] + self.benchmark\n",
        "        sell = self.sp_index[self.counter] - self.benchmark\n",
        "        self.df.loc[self.df[f'{year+1} PRICE VAR [%]']>buy, \"Class\"] = 2\n",
        "        self.df.loc[self.df[f'{year+1} PRICE VAR [%]']<sell, \"Class\"] = 0\n",
        "        self.df.loc[(self.df[f'{year+1} PRICE VAR [%]'] >= sell) & (self.df[f'{year+1} PRICE VAR [%]']<=buy), \"Class\"] = 1\n",
        "        # drop rows with no info\n",
        "        print('Dropping rows with NaNs only', end=' - ')\n",
        "        rows = self.df.shape[0]\n",
        "        self.df.dropna(how='all', inplace=True)\n",
        "        print(f'{self.df.shape[0] - rows} rows dropped - COMPLETE')\n",
        "\n",
        "        self.__print_summary(f'Initial DataFrame shape: {self.df.shape}')\n",
        "\n",
        "    def store_drop_class_col(self):\n",
        "        self.class_col = self.df['Class'].astype('int8')\n",
        "        self.df.drop(columns=['Class'], inplace=True)\n",
        "\n",
        "    def store_factorize_sector_col(self):\n",
        "        self.sector_col = self.df['Sector']\n",
        "        self.sector_ids, self.sector_mapper = pd.factorize(self.df['Sector'])\n",
        "        self.df['Sector'] = self.sector_ids\n",
        "\n",
        "    def factorize_col(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        sector_ids, self.sector_mapper = pd.factorize(df['Sector'])\n",
        "        df['Sector'] = sector_ids\n",
        "        df['Sector'] = df['Sector'].astype('float32')\n",
        "        return df\n",
        "\n",
        "    def handle_nans(self, round: int = 1):\n",
        "        if round == 1 and self.nan_handler:\n",
        "            self.__print_header(f'HANDLING NANS')\n",
        "\n",
        "        if 'threshold' in self.nan_handler:\n",
        "            nans_thres = self.config_dict[self.year]['nans_thres']\n",
        "            print(f'Dropping columns with more than {int(nans_thres * 100)}% NaNs', end=' - ')\n",
        "            cols = self.df.shape[1]\n",
        "            self.df = self.df.loc[:, self.df.isnull().mean() < nans_thres]  # drop nans\n",
        "            print(f'{cols - self.df.shape[1]} columns dropped - COMPLETE')\n",
        "            self.__print_sep(60, '~', '\\n')\n",
        "\n",
        "    def handle_zeros(self):\n",
        "        self.__print_header(f'HANDLING ZEROS')\n",
        "\n",
        "        if 'threshold' in self.zero_handler:\n",
        "            zeros_thres = self.config_dict[self.year]['zeros_thres']\n",
        "            print(f'Dropping columns with more than {int(zeros_thres * 100)}% zeros', end=' - ')\n",
        "            cols = self.df.shape[1]\n",
        "            self.df = self.df.loc[:, (self.df == 0).mean() < zeros_thres]  # drop zeros\n",
        "            print(f'{cols - self.df.shape[1]} columns dropped - COMPLETE')\n",
        "\n",
        "        if 'replace' in self.zero_handler:\n",
        "            print(f'Replacing zeros with NaNs', end=' - ')\n",
        "            z_count = (self.df == 0).sum().sum()\n",
        "            self.df = self.df.replace({0: np.nan})\n",
        "            z_count_after = (self.df == 0).sum().sum()\n",
        "            print(f'{z_count - z_count_after} zeros replaced - COMPLETE')\n",
        "\n",
        "        if 'replace' in self.zero_handler and 'drop_again' in self.zero_handler:\n",
        "            self.handle_nans(round=2)\n",
        "\n",
        "        da = self.init_shape[1] - self.df.shape[1]\n",
        "        sc = self.df.shape\n",
        "        self.__print_summary(f'Total amount of columns dropped: {da} - Current shape: {sc}')\n",
        "\n",
        "    def impute_nans(self):\n",
        "        self.__print_header(f'IMPUTE NANS')\n",
        "\n",
        "        if self.imputation_handler == 'KNN':\n",
        "            print(f'Imputing {self.df.isnull().sum().sum()} NaNs with KNN', end=' - ')\n",
        "            imputer = KNNImputer(n_neighbors=20, weights='distance', metric='nan_euclidean', copy=True)\n",
        "            np_imp = imputer.fit_transform(self.df)\n",
        "            self.df = pd.DataFrame(np_imp, columns=self.df.columns, index=self.df.index)\n",
        "            print(f'{self.df.isnull().sum().sum()} NaNs left - COMPLETE')\n",
        "\n",
        "        elif self.imputation_handler == 'XGB':\n",
        "            print(f'Imputing {self.df.isnull().sum().sum()} NaNs with XGB', end=' - ')\n",
        "            imputer = NaNImputer(verbose=False, multiprocessing_load=1)\n",
        "            self.df = imputer.impute(self.df)\n",
        "            print(f'{self.df.isnull().sum().sum()} NaNs left - COMPLETE')\n",
        "            cols = self.df.shape[1]\n",
        "            self.df.dropna(axis=1, inplace=True)  # remove columns that still have NaNs inside\n",
        "            print(f'Removing {cols - self.df.shape[1]} columns such that', end=' ')\n",
        "            print(f'{self.df.isnull().sum().sum()} NaNs are left - COMPLETE')\n",
        "\n",
        "        elif self.imputation_handler == 'mean':\n",
        "            print(f'Imputing NaNs with mean')\n",
        "\n",
        "            # drop rows where the 'Revenue' is unknown (NaNs)\n",
        "            print(f'Dropping rows that have no information about revenue', end=' - ')\n",
        "            rows = self.df.shape[0]\n",
        "            self.df.drop(self.df[self.df['Revenue'].isnull()].index, inplace=True)\n",
        "            print(f'{rows - self.df.shape[0]} rows dropped - COMPLETE')\n",
        "\n",
        "            # introduce new column that describes revenue ranges\n",
        "            range_cond = [(self.df['Revenue'] <= 1e6),\n",
        "                          (self.df['Revenue'] > 1e6) & (self.df['Revenue'] <= 1e7),\n",
        "                          (self.df['Revenue'] > 1e7) & (self.df['Revenue'] <= 1e8),\n",
        "                          (self.df['Revenue'] > 1e8) & (self.df['Revenue'] <= 1e9),\n",
        "                          (self.df['Revenue'] > 1e9)]\n",
        "            self.df['Revenue Range'] = np.select(range_cond, [0, 1, 2, 3, 4])\n",
        "\n",
        "            # store sector column to add it after groupby\n",
        "            sector_col = self.df['Sector']\n",
        "\n",
        "            # group by sector and then revenue range and impute nans with means\n",
        "            nans_count = self.df.isnull().sum().sum()\n",
        "            self.df = self.df.groupby(['Sector', 'Revenue Range']).transform(lambda x: x.fillna(x.mean()))\n",
        "            nans_count_after = self.df.isnull().sum().sum()\n",
        "            print(f'{nans_count - nans_count_after} NaNs imputed', end=' - ')\n",
        "            print(f'{nans_count_after} NaNs left - COMPLETE')\n",
        "\n",
        "            # add sector column again\n",
        "            self.df['Sector'] = sector_col\n",
        "\n",
        "            # if there are still NaNs left, remove the corresponding row(s)\n",
        "            if nans_count_after > 0:\n",
        "                print(f'Dropping rows with remaining NaNs', end=' - ')\n",
        "                row_count = self.df.shape[0]\n",
        "                self.df = self.df.dropna(axis=0)\n",
        "                print(f'{row_count - self.df.shape[0]} row(s) dropped', end=' - ')\n",
        "                print(f'{self.df.isnull().sum().sum()} NaNs left - COMPLETE')\n",
        "\n",
        "        self.__print_sep(60, '~', '\\n')\n",
        "\n",
        "    def handle_outliers(self):\n",
        "        self.__print_header('HANDLE OUTLIERS')\n",
        "\n",
        "        if 'quantile' in self.outlier_handler:\n",
        "            rows_before = self.df.shape[0]\n",
        "            cut_lower = self.config_dict[self.year]['cut_lower']\n",
        "            cut_upper = self.config_dict[self.year]['cut_upper']\n",
        "            # drop rows with an unnaturally high price variance\n",
        "            print(f'Dropping rows with a price variance outside the {cut_lower} - {cut_upper} quantile range',\n",
        "                  end=' - ')\n",
        "            col = f'{self.year + 1} PRICE VAR [%]'\n",
        "            outs = self.df[col].between(self.df[col].quantile(cut_lower),\n",
        "                                        self.df[col].quantile(cut_upper))\n",
        "            self.df.drop(self.df[~outs].index, inplace=True)\n",
        "            print(f'{rows_before - self.df.shape[0]} rows dropped - COMPLETE')\n",
        "\n",
        "        if 'IForest' in self.outlier_handler:\n",
        "            print('Using Isolation Forest to detect outliers', end=' - ')\n",
        "            contamination = self.config_dict[self.year]['IForest_contamination']\n",
        "            clf = IForest(contamination=contamination,\n",
        "                          random_state=42,\n",
        "                          n_jobs=-1)\n",
        "            clf.fit(self.df.values)\n",
        "            y_pred = clf.predict(self.df.values)\n",
        "            idx_y_pred = [i for i in range(self.df.shape[0]) if y_pred[i] == 0]\n",
        "            self.df = self.df.iloc[idx_y_pred, :]\n",
        "            print(f'{sum(y_pred)} outliers removed - COMPLETE')\n",
        "\n",
        "        self.__print_sep(60, '~', '\\n')\n",
        "\n",
        "    def scale_data(self):\n",
        "        self.__print_header('SCALING DATA')\n",
        "\n",
        "        print(f'Scaling data', end=' - ')\n",
        "        sector_col = self.df['Sector'] if 'Sector' in self.df.columns else None\n",
        "        scaler = StandardScaler()\n",
        "        np_scaled = scaler.fit_transform(self.df)\n",
        "        self.df = pd.DataFrame(np_scaled,\n",
        "                               columns=self.df.columns,\n",
        "                               index=self.df.index)\n",
        "\n",
        "        if sector_col is not None:\n",
        "            self.df['Sector'] = sector_col\n",
        "        print('COMPLETE')\n",
        "\n",
        "    def drop_var_col(self):\n",
        "        self.df.drop(columns=[f'{self.year + 1} PRICE VAR [%]'], inplace=True)\n",
        "\n",
        "    def convert_join(self):\n",
        "        # convert to float32\n",
        "        self.df = self.df.astype('float32')\n",
        "\n",
        "        # join 'Class' column\n",
        "        self.df = self.df.join(self.class_col)\n",
        "\n",
        "        self.__print_summary(f'Final DataFrame shape: {self.df.shape}')\n",
        "\n",
        "    def map_sector_inv(self):\n",
        "        mapper = {i: sector for i, sector in enumerate(self.sector_mapper)}\n",
        "        self.df['Sector'] = self.df['Sector'].apply(lambda x: mapper[x])\n",
        "\n",
        "    def get_intersecting_columns(self):\n",
        "        df1 = self.dfs[0].columns\n",
        "        df2 = self.dfs[1].columns\n",
        "        df3 = self.dfs[2].columns\n",
        "        df4 = self.dfs[3].columns\n",
        "        df5 = self.dfs[4].columns\n",
        "\n",
        "        self.intersec_cols = df1 & df2 & df3 & df4 & df5\n",
        "        print(f'Found {len(self.intersec_cols)} intersecting columns!')\n",
        "\n",
        "    def concat_intersecting_dfs(self):\n",
        "        df1 = self.dfs[0][self.intersec_cols]\n",
        "        df2 = self.dfs[1][self.intersec_cols]\n",
        "        df3 = self.dfs[2][self.intersec_cols]\n",
        "        df4 = self.dfs[3][self.intersec_cols]\n",
        "        df5 = self.dfs[4][self.intersec_cols]\n",
        "\n",
        "        df = pd.concat([df1, df2, df3, df4, df5])\n",
        "        print(f'Concatenated DataFrame into shape: {df.shape}')\n",
        "\n",
        "        return df\n",
        "\n",
        "    def __print_summary(self, info: str):\n",
        "        self.__print_sep()\n",
        "        print(info)\n",
        "        self.__print_sep(60, '~', '\\n')\n",
        "\n",
        "    def __print_sep(self, n: int = 60, c: str = '-', nl: str = ''):\n",
        "        print(n * c + nl)\n",
        "\n",
        "    def __print_header(self, header: str):\n",
        "        rem = 60 - 25 - 2 - len(header)\n",
        "        print(f'{25 * \"~\"} {header} {rem * \"~\"}')"
      ],
      "metadata": {
        "id": "Qb_W1JWaj498"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare approaches"
      ],
      "metadata": {
        "id": "HNHa5JNemgs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set config dictionary"
      ],
      "metadata": {
        "id": "KhDP7N_Bs9Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_dict = {\n",
        "    2014: {\n",
        "        'nans_thres': 0.08, \n",
        "        'zeros_thres': 0.08,\n",
        "        'cut_lower': 0.01,\n",
        "        'cut_upper': 0.99,\n",
        "        'IForest_contamination': 0.02\n",
        "    },\n",
        "    2015: {\n",
        "        'nans_thres': 0.10, \n",
        "        'zeros_thres': 0.08,\n",
        "        'cut_lower': 0.01,\n",
        "        'cut_upper': 0.99,\n",
        "        'IForest_contamination': 0.02\n",
        "    },\n",
        "    2016: {\n",
        "        'nans_thres': 0.16, \n",
        "        'zeros_thres': 0.08,\n",
        "        'cut_lower': 0.01,\n",
        "        'cut_upper': 0.99,\n",
        "        'IForest_contamination': 0.02\n",
        "    },\n",
        "    2017: {\n",
        "        'nans_thres': 0.16, \n",
        "        'zeros_thres': 0.08,\n",
        "        'cut_lower': 0.01,\n",
        "        'cut_upper': 0.99,\n",
        "        'IForest_contamination': 0.02\n",
        "    },\n",
        "    2018: {\n",
        "        'nans_thres': 0.08, \n",
        "        'zeros_thres': 0.08,\n",
        "        'cut_lower': 0.01,\n",
        "        'cut_upper': 0.99,\n",
        "        'IForest_contamination': 0.02\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "4OwwwrQwgiO-"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 1\n",
        "\n",
        "1.   *NaN threshold*\n",
        "2.   *zero threshold*\n",
        "3.   *mean imputation*\n",
        "4.   *outlier quantile cut*\n",
        "\n"
      ],
      "metadata": {
        "id": "otz1ng9emkbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = pd.read_csv(\"/content/2014_Financial_Data.csv\")\n"
      ],
      "metadata": {
        "id": "Lni6vyS2hqx6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_1 = DataSet(config_dict=config_dict,\n",
        "                    nan_handler = ['threshold'],\n",
        "                    zero_handler = ['threshold'],\n",
        "                    imputation_handler = 'mean',\n",
        "                    outlier_handler = ['quantile'])\n",
        "\n",
        "# generate DataFrame\n",
        "df_1 = dataset_1.create_dataset()\n",
        "\n",
        "# use full df for cross validation vanilla test\n",
        "X_1, y_1 = df_1.drop(columns=['Class']), df_1['Class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_1, y_1, test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyMm5zQ8gZnV",
        "outputId": "c4407faa-d883-435f-ec9e-6bf55e2367ac"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2014 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2014_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (3808, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING NANS ~~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% NaNs - 89 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 60 columns dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 150 - Current shape: (3808, 74)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing NaNs with mean\n",
            "Dropping rows that have no information about revenue - 44 rows dropped - COMPLETE\n",
            "8163 NaNs imputed - 0 NaNs left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 76 rows dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (3688, 74)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2015 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2015_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4120, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING NANS ~~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 10% NaNs - 68 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 67 columns dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 136 - Current shape: (4120, 88)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing NaNs with mean\n",
            "Dropping rows that have no information about revenue - 67 rows dropped - COMPLETE\n",
            "16665 NaNs imputed - 0 NaNs left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 82 rows dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (3971, 88)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2016 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2016_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4797, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING NANS ~~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 16% NaNs - 97 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 61 columns dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 159 - Current shape: (4797, 65)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing NaNs with mean\n",
            "Dropping rows that have no information about revenue - 489 rows dropped - COMPLETE\n",
            "9768 NaNs imputed - 10 NaNs left - COMPLETE\n",
            "Dropping rows with remaining NaNs - 1 row(s) dropped - 0 NaNs left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 88 rows dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4219, 65)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2017 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2017_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4960, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING NANS ~~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 16% NaNs - 145 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 31 columns dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 177 - Current shape: (4960, 47)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing NaNs with mean\n",
            "Dropping rows that have no information about revenue - 525 rows dropped - COMPLETE\n",
            "5506 NaNs imputed - 0 NaNs left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 90 rows dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4345, 47)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2018 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2018_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4392, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING NANS ~~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% NaNs - 62 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 70 columns dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 133 - Current shape: (4392, 91)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing NaNs with mean\n",
            "Dropping rows that have no information about revenue - 46 rows dropped - COMPLETE\n",
            "14056 NaNs imputed - 0 NaNs left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 88 rows dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4258, 91)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "############################################################\n",
            "\n",
            "Found 42 intersecting columns!\n",
            "Concatenated DataFrame into shape: (20481, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_vanilla(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Cw4By1i5oz-e",
        "outputId": "d4832a85-977f-49aa-bfdd-009b0152015c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-49f03fc05be5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_vanilla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-3ac1ae34d10d>\u001b[0m in \u001b[0;36mtest_vanilla\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     45\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                               n_jobs=-1)\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{metric} for {name}: {grid.score(X_test, y_test)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 2\n",
        "\n",
        "\n",
        "1.   *zero threshold*\n",
        "2.   *replace zeros with NaNs*\n",
        "3.   *KNN imputation*\n",
        "4.   *outlier quantile cut*\n",
        "5.   *Isolation Forest outlier handling*\n",
        "\n"
      ],
      "metadata": {
        "id": "H4SGEHkIo7kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_2 = DataSet(config_dict=config_dict,\n",
        "                    nan_handler = [],\n",
        "                    zero_handler = ['threshold', 'replace'],\n",
        "                    imputation_handler = 'KNN',\n",
        "                    outlier_handler = ['quantile', 'IForest'])\n",
        "\n",
        "# generate DataFrame\n",
        "df_2 = dataset_2.create_dataset()\n",
        "\n",
        "# use full df for cross validation vanilla test\n",
        "X_2, y_2 = df_2.drop(columns=['Class']), df_2['Class']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNjNTA_PqSil",
        "outputId": "4d357811-faf3-46fd-91f9-42716f5cd5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2014 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2014_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (3808, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 87 columns dropped - COMPLETE\n",
            "Replacing zeros with NaNs - 7842 zeros replaced - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 88 - Current shape: (3808, 136)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 77059 NaNs with KNN - 0 NaNs left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 78 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 75 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (3655, 136)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2015 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2015_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4120, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 84 columns dropped - COMPLETE\n",
            "Replacing zeros with NaNs - 8989 zeros replaced - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 85 - Current shape: (4120, 139)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 87684 NaNs with KNN - 0 NaNs left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 84 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 81 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (3955, 139)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2016 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2016_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4797, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 84 columns dropped - COMPLETE\n",
            "Replacing zeros with NaNs - 10615 zeros replaced - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 85 - Current shape: (4797, 139)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 150611 NaNs with KNN - 0 NaNs left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 96 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 94 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4607, 139)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2017 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2017_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4960, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 84 columns dropped - COMPLETE\n",
            "Replacing zeros with NaNs - 10279 zeros replaced - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 85 - Current shape: (4960, 139)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 158663 NaNs with KNN - 0 NaNs left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 100 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 98 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4762, 139)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2018 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2018_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4392, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 87 columns dropped - COMPLETE\n",
            "Replacing zeros with NaNs - 8561 zeros replaced - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 88 - Current shape: (4392, 136)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 75465 NaNs with KNN - 0 NaNs left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 88 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 87 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4217, 136)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "############################################################\n",
            "\n",
            "Found 133 intersecting columns!\n",
            "Concatenated DataFrame into shape: (21196, 133)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_vanilla(X_2, y_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "MKZb3loZrFCr",
        "outputId": "0eb97889-a384-4db9-efc3-3c97d2961e64"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-13689e72d3a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_vanilla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 3\n",
        "\n",
        "1.   *replace zeros with NaNs*\n",
        "3.   *XGB imputation*\n",
        "4.   *outlier quantile cut*\n",
        "5.   *Isolation Forest outlier handling*\n"
      ],
      "metadata": {
        "id": "cKkOx65LrH0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_3 = DataSet(config_dict=config_dict,\n",
        "                    nan_handler = [],\n",
        "                    zero_handler = ['replace'],\n",
        "                    imputation_handler = 'XGB',\n",
        "                    outlier_handler = ['quantile', 'IForest'])\n",
        "\n",
        "# generate DataFrame\n",
        "df_3 = dataset_3.create_dataset()\n",
        "\n",
        "# use full df for cross validation vanilla test\n",
        "X_3, y_3= df_3.drop(columns=['Class']), df_3['Class']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L-dLVG_8rceJ",
        "outputId": "eac1f467-cf05-43ca-878f-626369f49e84"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2014 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2014_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "            Revenue  Revenue Growth  Cost of Revenue  Gross Profit  \\\n",
            "PG     7.440100e+10         -0.0713     3.903000e+10  3.537100e+10   \n",
            "VIPS   3.734148e+09          1.1737     2.805625e+09  9.285226e+08   \n",
            "KR     9.837500e+10          0.0182     7.813800e+10  2.023700e+10   \n",
            "RAD    2.552641e+10          0.0053     1.820268e+10  7.323734e+09   \n",
            "GIS    1.790960e+10          0.0076     1.153980e+10  6.369800e+09   \n",
            "...             ...             ...              ...           ...   \n",
            "TSRI   4.952987e+07          0.1028     4.125164e+07  8.278229e+06   \n",
            "TZOO   1.532400e+08         -0.1019     1.917400e+07  1.340660e+08   \n",
            "USATP  4.200000e+07             NaN     2.700000e+07  1.500000e+07   \n",
            "WSTG   3.407580e+08          0.1344     3.159480e+08  2.481000e+07   \n",
            "WTT    4.033737e+07          0.1925     2.129368e+07  1.904369e+07   \n",
            "\n",
            "       R&D Expenses  SG&A Expense  Operating Expenses  Operating Income  \\\n",
            "PG     0.000000e+00  2.146100e+10        2.146100e+10      1.391000e+10   \n",
            "VIPS   1.083303e+08  3.441414e+08        7.939267e+08      1.345959e+08   \n",
            "KR     0.000000e+00  1.519600e+10        1.751200e+10      2.725000e+09   \n",
            "RAD    0.000000e+00  6.561162e+09        6.586482e+09      7.372520e+08   \n",
            "GIS    0.000000e+00  3.474300e+09        3.412400e+09      2.957400e+09   \n",
            "...             ...           ...                 ...               ...   \n",
            "TSRI   0.000000e+00  8.253061e+06        8.253061e+06      2.516800e+04   \n",
            "TZOO   1.132600e+07  1.125130e+08        1.162560e+08      1.781000e+07   \n",
            "USATP           NaN  1.400000e+07        1.500000e+07      0.000000e+00   \n",
            "WSTG   0.000000e+00  1.651300e+07        1.651300e+07      8.297000e+06   \n",
            "WTT    3.379920e+06  1.098477e+07        1.436469e+07      4.679002e+06   \n",
            "\n",
            "       Interest Expense  Earnings before Tax  ...  Receivables growth  \\\n",
            "PG         7.090000e+08         1.449400e+10  ...             -0.0187   \n",
            "VIPS       1.214869e+07         1.753823e+08  ...                 NaN   \n",
            "KR         4.430000e+08         2.270000e+09  ...              0.0618   \n",
            "RAD        4.245910e+08         2.502180e+08  ...              0.0211   \n",
            "GIS        3.024000e+08         2.707700e+09  ...              0.0257   \n",
            "...                 ...                  ...  ...                 ...   \n",
            "TSRI       0.000000e+00        -6.893600e+04  ...             -0.0384   \n",
            "TZOO       0.000000e+00         1.790100e+07  ...              0.1529   \n",
            "USATP      0.000000e+00         0.000000e+00  ...                 NaN   \n",
            "WSTG      -4.720000e+05         8.758000e+06  ...             -0.0333   \n",
            "WTT        0.000000e+00         4.588870e+06  ...             -0.0469   \n",
            "\n",
            "       Inventory Growth  Asset Growth  Book Value per Share Growth  \\\n",
            "PG              -0.0217        0.0359                       0.0316   \n",
            "VIPS                NaN           NaN                          NaN   \n",
            "KR               0.0981        0.1886                       0.3268   \n",
            "RAD             -0.0510       -0.0189                       0.1963   \n",
            "GIS              0.0090        0.0215                       0.0274   \n",
            "...                 ...           ...                          ...   \n",
            "TSRI             0.0000       -0.0041                      -0.0049   \n",
            "TZOO             0.0000       -0.1872                       0.1823   \n",
            "USATP               NaN           NaN                          NaN   \n",
            "WSTG             0.1338        0.0023                       0.0890   \n",
            "WTT              0.0455       -0.1646                      -0.0226   \n",
            "\n",
            "       Debt Growth  R&D Expense Growth  SG&A Expenses Growth  \\\n",
            "PG          0.1228              0.0000               -0.1746   \n",
            "VIPS           NaN              1.6484                1.7313   \n",
            "KR          0.2738              0.0000                0.0234   \n",
            "RAD        -0.0458              0.0000               -0.0060   \n",
            "GIS         0.1025              0.0000               -0.0220   \n",
            "...            ...                 ...                   ...   \n",
            "TSRI        0.0000              0.0000                0.0213   \n",
            "TZOO        0.0000              0.2830               -0.0637   \n",
            "USATP          NaN                 NaN                   NaN   \n",
            "WSTG        0.0000              0.0000                0.0650   \n",
            "WTT        -0.4594              0.2778               -0.0268   \n",
            "\n",
            "                   Sector  2015 PRICE VAR [%]  Class  \n",
            "PG     Consumer Defensive           -9.323276      0  \n",
            "VIPS   Consumer Defensive          -25.512193      0  \n",
            "KR     Consumer Defensive           33.118297      2  \n",
            "RAD    Consumer Defensive            2.752291      2  \n",
            "GIS    Consumer Defensive           12.897715      2  \n",
            "...                   ...                 ...    ...  \n",
            "TSRI           Technology           29.362884      2  \n",
            "TZOO           Technology          -31.167763      0  \n",
            "USATP          Technology          -23.558900      0  \n",
            "WSTG           Technology            7.779579      2  \n",
            "WTT            Technology          -34.099613      0  \n",
            "\n",
            "[3808 rows x 224 columns]\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (3808, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Replacing zeros with NaNs - 113537 zeros replaced - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 1 - Current shape: (3808, 223)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 214640 NaNs with XGB - NaNImputer(conservative = False, n_feats = 10,            \n",
            "           fix_string_nans = True, verbose = False,                \n",
            "           multiprocessing_load = 1, fill_nans_in_pure_text = True,                    \n",
            "           drop_empty_cols = True, drop_nan_cols_with_constant = True                        \n",
            "           feature_selection = correlation)\n",
            "\n",
            "Impute sequentially on a single core\n",
            "\n",
            "824 NaNs left - COMPLETE\n",
            "Removing 3 columns such that 0 NaNs are left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 78 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 75 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (3655, 217)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2015 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2015_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "            Revenue  Revenue Growth  Cost of Revenue  Gross Profit  \\\n",
            "PG     7.074900e+10         -0.0491     3.705600e+10  3.369300e+10   \n",
            "VIPS   6.193685e+09          0.6587     4.669038e+09  1.524648e+09   \n",
            "KR     1.084650e+11          0.1026     8.551200e+10  2.295300e+10   \n",
            "RAD    2.652838e+10          0.0393     1.895164e+10  7.576732e+09   \n",
            "GIS    1.763030e+10         -0.0156     1.168110e+10  5.949200e+09   \n",
            "...             ...             ...              ...           ...   \n",
            "TSRI   5.740290e+07          0.1590     4.808743e+07  9.315468e+06   \n",
            "TZOO   1.239610e+08         -0.1911     1.814800e+07  1.058130e+08   \n",
            "USATP  5.800000e+07             NaN     4.100000e+07  1.700000e+07   \n",
            "WSTG   3.820900e+08          0.1213     3.555170e+08  2.657300e+07   \n",
            "WTT    3.310911e+07         -0.1792     1.828123e+07  1.482787e+07   \n",
            "\n",
            "       R&D Expenses  SG&A Expense  Operating Expenses  Operating Income  \\\n",
            "PG     0.000000e+00  2.061600e+10        2.264400e+10      1.104900e+10   \n",
            "VIPS   1.658481e+08  5.223879e+08        1.205660e+09      3.189877e+08   \n",
            "KR     0.000000e+00  1.716100e+10        1.981600e+10      3.137000e+09   \n",
            "RAD    0.000000e+00  6.695642e+09        6.733788e+09      8.429440e+08   \n",
            "GIS    0.000000e+00  3.328000e+09        3.871900e+09      2.077300e+09   \n",
            "...             ...           ...                 ...               ...   \n",
            "TSRI   0.000000e+00  8.883003e+06        8.883003e+06      4.324650e+05   \n",
            "TZOO   1.221400e+07  8.977900e+07        1.019930e+08      3.820000e+06   \n",
            "USATP           NaN  1.600000e+07        1.700000e+07     -0.000000e+00   \n",
            "WSTG   0.000000e+00  1.806300e+07        1.806300e+07      8.510000e+06   \n",
            "WTT    3.957274e+06  1.012356e+07        1.408084e+07      7.470390e+05   \n",
            "\n",
            "       Interest Expense  Earnings before Tax  ...  Receivables growth  \\\n",
            "PG         6.260000e+08         9.761000e+09  ...             -0.2847   \n",
            "VIPS       1.321245e+07         3.154229e+08  ...             28.6759   \n",
            "KR         4.880000e+08         2.630000e+09  ...              0.1344   \n",
            "RAD        3.976120e+08         4.268200e+08  ...              0.0336   \n",
            "GIS        3.154000e+08         1.808100e+09  ...             -0.0653   \n",
            "...                 ...                  ...  ...                 ...   \n",
            "TSRI       0.000000e+00         3.447110e+05  ...             -0.0048   \n",
            "TZOO       0.000000e+00         4.919000e+06  ...              0.0170   \n",
            "USATP      0.000000e+00        -1.000000e+06  ...                 NaN   \n",
            "WSTG      -3.680000e+05         8.858000e+06  ...             -0.0306   \n",
            "WTT        0.000000e+00         7.226210e+05  ...              0.0675   \n",
            "\n",
            "       Inventory Growth  Asset Growth  Book Value per Share Growth  \\\n",
            "PG              -0.2634       -0.1024                      -0.1013   \n",
            "VIPS             0.2144        0.1279                       0.2946   \n",
            "KR               0.0065        0.0415                       0.0535   \n",
            "RAD             -0.0371        0.2639                       1.0266   \n",
            "GIS             -0.0119       -0.0568                      -0.2118   \n",
            "...                 ...           ...                          ...   \n",
            "TSRI             0.0000        0.0360                       0.0220   \n",
            "TZOO             0.0000       -0.2650                      -0.4011   \n",
            "USATP               NaN           NaN                          NaN   \n",
            "WSTG             0.3105       -0.0095                      -0.0173   \n",
            "WTT             -0.0553       -0.0436                       0.0347   \n",
            "\n",
            "       Debt Growth  R&D Expense Growth  SG&A Expenses Growth  \\\n",
            "PG         -0.1432              0.0000               -0.0394   \n",
            "VIPS        0.0281              0.5309                0.5179   \n",
            "KR          0.0254              0.0000                0.1293   \n",
            "RAD        -0.0344              0.0000                0.0205   \n",
            "GIS         0.0462              0.0000               -0.0421   \n",
            "...            ...                 ...                   ...   \n",
            "TSRI        0.0000              0.0000                0.0763   \n",
            "TZOO        4.6580              0.0784               -0.2021   \n",
            "USATP          NaN                 NaN                   NaN   \n",
            "WSTG        0.0000              0.0000                0.0939   \n",
            "WTT         1.3011              0.1708               -0.0784   \n",
            "\n",
            "                   Sector  2016 PRICE VAR [%]  Class  \n",
            "PG     Consumer Defensive           10.809451      1  \n",
            "VIPS   Consumer Defensive          -21.637010      0  \n",
            "KR     Consumer Defensive          -15.036503      0  \n",
            "RAD    Consumer Defensive            4.303799      0  \n",
            "GIS    Consumer Defensive           10.693172      1  \n",
            "...                   ...                 ...    ...  \n",
            "TSRI           Technology           33.101842      2  \n",
            "TZOO           Technology           13.801445      2  \n",
            "USATP          Technology           34.769228      2  \n",
            "WSTG           Technology            6.050663      0  \n",
            "WTT            Technology           17.177912      2  \n",
            "\n",
            "[4120 rows x 224 columns]\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4120, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Replacing zeros with NaNs - 120324 zeros replaced - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 1 - Current shape: (4120, 223)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 234672 NaNs with XGB - NaNImputer(conservative = False, n_feats = 10,            \n",
            "           fix_string_nans = True, verbose = False,                \n",
            "           multiprocessing_load = 1, fill_nans_in_pure_text = True,                    \n",
            "           drop_empty_cols = True, drop_nan_cols_with_constant = True                        \n",
            "           feature_selection = correlation)\n",
            "\n",
            "Impute sequentially on a single core\n",
            "\n",
            "5825 NaNs left - COMPLETE\n",
            "Removing 5 columns such that 0 NaNs are left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 84 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 81 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (3955, 217)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2016 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2016_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "            Revenue  Revenue Growth  Cost of Revenue  Gross Profit  \\\n",
            "PG     6.529900e+10         -0.0770     3.290900e+10  3.239000e+10   \n",
            "VIPS   8.148496e+09          0.3156     6.190740e+09  1.957756e+09   \n",
            "KR     1.098300e+11          0.0126     8.549600e+10  2.433400e+10   \n",
            "RAD    2.077024e+10         -0.2171     1.577826e+10  4.991979e+09   \n",
            "GIS    1.656310e+10         -0.0605     1.073360e+10  5.829500e+09   \n",
            "...             ...             ...              ...           ...   \n",
            "TSRI   6.099828e+07          0.0626     5.103888e+07  9.959402e+06   \n",
            "TZOO   1.142630e+08         -0.0782     1.385500e+07  1.004080e+08   \n",
            "USATP  7.700000e+07             NaN     5.500000e+07  2.200000e+07   \n",
            "WSTG   1.646090e+08         -0.5692     1.372780e+08  2.733100e+07   \n",
            "WTT    3.132700e+07         -0.0538     1.816500e+07  1.316200e+07   \n",
            "\n",
            "       R&D Expenses  SG&A Expense  Operating Expenses  Operating Income  \\\n",
            "PG     0.000000e+00  1.894900e+10        1.894900e+10      1.344100e+10   \n",
            "VIPS   2.251378e+08  6.880959e+08        1.567877e+09      3.898789e+08   \n",
            "KR     0.000000e+00  1.794600e+10        2.075800e+10      3.576000e+09   \n",
            "RAD    0.000000e+00  4.581171e+09        4.621042e+09      3.709370e+08   \n",
            "GIS    0.000000e+00  3.118900e+09        3.270300e+09      2.559200e+09   \n",
            "...             ...           ...                 ...               ...   \n",
            "TSRI   0.000000e+00  9.120526e+06        9.120526e+06      8.388760e+05   \n",
            "TZOO   9.096000e+06  8.112600e+07        9.022200e+07      1.018600e+07   \n",
            "USATP           NaN  2.200000e+07        2.300000e+07     -1.000000e+06   \n",
            "WSTG   0.000000e+00  1.871500e+07        1.871500e+07      8.616000e+06   \n",
            "WTT    4.046000e+06  1.166400e+07        1.571000e+07     -2.548000e+06   \n",
            "\n",
            "       Interest Expense  Earnings before Tax  ...  Receivables growth  \\\n",
            "PG         5.790000e+08         1.385000e+10  ...             -0.0427   \n",
            "VIPS       1.226710e+07         3.799345e+08  ...              0.9234   \n",
            "KR         4.820000e+08         3.084000e+09  ...              0.3697   \n",
            "RAD        1.861320e+08         2.149770e+08  ...              0.6322   \n",
            "GIS        3.038000e+08         2.452600e+09  ...             -0.0187   \n",
            "...                 ...                  ...  ...                 ...   \n",
            "TSRI       0.000000e+00         7.882260e+05  ...             -0.1191   \n",
            "TZOO       0.000000e+00         1.062300e+07  ...             -0.1209   \n",
            "USATP      1.000000e+06        -7.000000e+06  ...                 NaN   \n",
            "WSTG      -3.180000e+05         8.933000e+06  ...              0.4233   \n",
            "WTT        0.000000e+00        -2.184000e+06  ...             -0.0490   \n",
            "\n",
            "       Inventory Growth  Asset Growth  Book Value per Share Growth  \\\n",
            "PG              -0.0528       -0.0182                      -0.0627   \n",
            "VIPS             0.0128        0.1706                       0.5109   \n",
            "KR               0.0844        0.1115                       0.2797   \n",
            "RAD             -0.0645        0.2848                       8.5628   \n",
            "GIS             -0.0825       -0.0055                      -0.0105   \n",
            "...                 ...           ...                          ...   \n",
            "TSRI             0.0000        0.0027                       0.0441   \n",
            "TZOO             0.0000       -0.2194                      -0.1115   \n",
            "USATP               NaN           NaN                          NaN   \n",
            "WSTG             0.1894        0.2085                       0.0012   \n",
            "WTT              0.0476        0.0210                       0.0088   \n",
            "\n",
            "       Debt Growth  R&D Expense Growth  SG&A Expenses Growth  \\\n",
            "PG          0.0083              0.0000               -0.0809   \n",
            "VIPS       -0.0139              0.3575                0.3172   \n",
            "KR          0.0416              0.0000                0.0457   \n",
            "RAD         0.2581              0.0000               -0.3158   \n",
            "GIS        -0.0828              0.0000               -0.0628   \n",
            "...            ...                 ...                   ...   \n",
            "TSRI        0.0000              0.0000                0.0267   \n",
            "TZOO       -1.0000             -0.2553               -0.0964   \n",
            "USATP          NaN                 NaN                   NaN   \n",
            "WSTG        0.0000              0.0000                0.0361   \n",
            "WTT        -1.0000              0.0224                0.1522   \n",
            "\n",
            "                   Sector  2017 PRICE VAR [%]  Class  \n",
            "PG     Consumer Defensive           12.532463      0  \n",
            "VIPS   Consumer Defensive            4.363319      0  \n",
            "KR     Consumer Defensive          -17.068252      0  \n",
            "RAD    Consumer Defensive          -75.916870      0  \n",
            "GIS    Consumer Defensive           -1.162942      0  \n",
            "...                   ...                 ...    ...  \n",
            "TSRI           Technology            0.655807      0  \n",
            "TZOO           Technology          -35.500002      0  \n",
            "USATP          Technology           14.840183      0  \n",
            "WSTG           Technology           -2.854095      0  \n",
            "WTT            Technology           29.946527      2  \n",
            "\n",
            "[4797 rows x 224 columns]\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4797, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Replacing zeros with NaNs - 130018 zeros replaced - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 1 - Current shape: (4797, 223)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 342567 NaNs with XGB - NaNImputer(conservative = False, n_feats = 10,            \n",
            "           fix_string_nans = True, verbose = False,                \n",
            "           multiprocessing_load = 1, fill_nans_in_pure_text = True,                    \n",
            "           drop_empty_cols = True, drop_nan_cols_with_constant = True                        \n",
            "           feature_selection = correlation)\n",
            "\n",
            "Impute sequentially on a single core\n",
            "\n",
            "3577 NaNs left - COMPLETE\n",
            "Removing 4 columns such that 0 NaNs are left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 96 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 94 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4607, 218)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2017 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2017_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "            Revenue  Revenue Growth  Cost of Revenue  Gross Profit  \\\n",
            "PG     6.505800e+10         -0.0037     3.263800e+10  3.242000e+10   \n",
            "VIPS   1.102060e+10          0.3525     8.557810e+09  2.462794e+09   \n",
            "KR     1.153370e+11          0.0501     8.950200e+10  2.583500e+10   \n",
            "RAD    2.292754e+10          0.1039     1.786283e+10  5.064707e+09   \n",
            "GIS    1.561980e+10         -0.0570     1.005200e+10  5.567800e+09   \n",
            "...             ...             ...              ...           ...   \n",
            "TSRI   6.257258e+07          0.0258     5.232652e+07  1.024606e+07   \n",
            "TZOO   1.065240e+08         -0.0677     1.290900e+07  9.361500e+07   \n",
            "USATP  1.040000e+08             NaN     7.700000e+07  2.700000e+07   \n",
            "WSTG   1.605670e+08         -0.0246     1.334910e+08  2.707600e+07   \n",
            "WTT    4.607800e+07          0.4709     2.681700e+07  1.926100e+07   \n",
            "\n",
            "       R&D Expenses  SG&A Expense  Operating Expenses  Operating Income  \\\n",
            "PG     0.000000e+00  1.865400e+10        1.865400e+10      1.376600e+10   \n",
            "VIPS   2.733452e+08  8.201852e+08        2.056136e+09      4.066575e+08   \n",
            "KR     0.000000e+00  1.916200e+10        2.238300e+10      3.452000e+09   \n",
            "RAD    0.000000e+00  4.776995e+09        4.816124e+09      2.485830e+08   \n",
            "GIS    0.000000e+00  2.888800e+09        3.069200e+09      2.498600e+09   \n",
            "...             ...           ...                 ...               ...   \n",
            "TSRI   0.000000e+00  9.683601e+06        9.683601e+06      5.624630e+05   \n",
            "TZOO   9.224000e+06  7.984600e+07        8.907000e+07      4.545000e+06   \n",
            "USATP           NaN  2.500000e+07        2.700000e+07      0.000000e+00   \n",
            "WSTG   0.000000e+00  1.926300e+07        1.926300e+07      7.813000e+06   \n",
            "WTT    4.395000e+06  1.798700e+07        2.238200e+07     -3.121000e+06   \n",
            "\n",
            "       Interest Expense  Earnings before Tax  ...  Receivables growth  \\\n",
            "PG         4.650000e+08         1.838900e+10  ...              0.0505   \n",
            "VIPS       1.245995e+07         3.893281e+08  ...              0.9219   \n",
            "KR         5.220000e+08         2.932000e+09  ...             -0.0490   \n",
            "RAD        2.000650e+08         4.849100e+07  ...              0.1063   \n",
            "GIS        2.951000e+08         2.312700e+09  ...              0.0509   \n",
            "...                 ...                  ...  ...                 ...   \n",
            "TSRI       0.000000e+00         5.311890e+05  ...             -0.0482   \n",
            "TZOO       0.000000e+00         6.656000e+06  ...             -0.1836   \n",
            "USATP      1.000000e+06        -2.000000e+06  ...                 NaN   \n",
            "WSTG      -6.990000e+05         8.553000e+06  ...             -0.0934   \n",
            "WTT        2.960000e+05        -3.246000e+06  ...              0.7440   \n",
            "\n",
            "       Inventory Growth  Asset Growth  Book Value per Share Growth  \\\n",
            "PG              -0.0195       -0.0529                       0.0012   \n",
            "VIPS             0.4764        0.5889                       1.5821   \n",
            "KR               0.0637        0.0769                       0.0071   \n",
            "RAD             -0.3365        0.0281                       0.0502   \n",
            "GIS              0.0494        0.0046                      -0.0943   \n",
            "...                 ...           ...                          ...   \n",
            "TSRI             0.0000        0.0316                      -0.1795   \n",
            "TZOO             0.0000       -0.1468                      -0.2138   \n",
            "USATP               NaN           NaN                          NaN   \n",
            "WSTG             0.2022       -0.0792                       0.0782   \n",
            "WTT             -0.2280        0.3241                       0.0233   \n",
            "\n",
            "       Debt Growth  R&D Expense Growth  SG&A Expenses Growth  \\\n",
            "PG          0.0325              0.0000               -0.0156   \n",
            "VIPS        0.3805              0.2141                0.1920   \n",
            "KR          0.1654              0.0000                0.0678   \n",
            "RAD        -0.5295              0.0000                0.0427   \n",
            "GIS         0.1246              0.0000               -0.0738   \n",
            "...            ...                 ...                   ...   \n",
            "TSRI        0.0000              0.0000                0.0617   \n",
            "TZOO        0.0000              0.0141               -0.0158   \n",
            "USATP          NaN                 NaN                   NaN   \n",
            "WSTG        0.0000              0.0000                0.0293   \n",
            "WTT         0.0000              0.0863                0.5421   \n",
            "\n",
            "                   Sector  2018 PRICE VAR [%]  Class  \n",
            "PG     Consumer Defensive            4.975151      2  \n",
            "VIPS   Consumer Defensive          -56.320000      0  \n",
            "KR     Consumer Defensive           -0.990449      2  \n",
            "RAD    Consumer Defensive          -66.666666      0  \n",
            "GIS    Consumer Defensive          -31.280412      0  \n",
            "...                   ...                 ...    ...  \n",
            "TSRI           Technology          -12.264152      0  \n",
            "TZOO           Technology           46.716421      2  \n",
            "USATP          Technology          -32.220041      0  \n",
            "WSTG           Technology          -36.405277      0  \n",
            "WTT            Technology          -27.755104      0  \n",
            "\n",
            "[4960 rows x 224 columns]\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4960, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Replacing zeros with NaNs - 132119 zeros replaced - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 1 - Current shape: (4960, 223)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 358388 NaNs with XGB - NaNImputer(conservative = False, n_feats = 10,            \n",
            "           fix_string_nans = True, verbose = False,                \n",
            "           multiprocessing_load = 1, fill_nans_in_pure_text = True,                    \n",
            "           drop_empty_cols = True, drop_nan_cols_with_constant = True                        \n",
            "           feature_selection = correlation)\n",
            "\n",
            "Impute sequentially on a single core\n",
            "\n",
            "0 NaNs left - COMPLETE\n",
            "Removing 0 columns such that 0 NaNs are left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 100 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 98 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4762, 222)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2018 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2018_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "            Revenue  Revenue Growth  Cost of Revenue  Gross Profit  \\\n",
            "CMCSA  9.450700e+10          0.1115     0.000000e+00  9.450700e+10   \n",
            "KMI    1.414400e+10          0.0320     7.288000e+09  6.856000e+09   \n",
            "INTC   7.084800e+10          0.1289     2.711100e+10  4.373700e+10   \n",
            "MU     3.039100e+10          0.4955     1.250000e+10  1.789100e+10   \n",
            "GE     1.216150e+11          0.0285     9.546100e+10  2.615400e+10   \n",
            "...             ...             ...              ...           ...   \n",
            "YRIV   0.000000e+00          0.0000     0.000000e+00  0.000000e+00   \n",
            "YTEN   5.560000e+05         -0.4110     0.000000e+00  5.560000e+05   \n",
            "ZKIN   5.488438e+07          0.2210     3.659379e+07  1.829059e+07   \n",
            "ZOM    0.000000e+00          0.0000     0.000000e+00  0.000000e+00   \n",
            "ZYME   5.301900e+07          0.0243     0.000000e+00  5.301900e+07   \n",
            "\n",
            "       R&D Expenses  SG&A Expense  Operating Expenses  Operating Income  \\\n",
            "CMCSA  0.000000e+00  6.482200e+10        7.549800e+10      1.900900e+10   \n",
            "KMI    0.000000e+00  6.010000e+08        3.062000e+09      3.794000e+09   \n",
            "INTC   1.354300e+10  6.750000e+09        2.042100e+10      2.331600e+10   \n",
            "MU     2.141000e+09  8.130000e+08        2.897000e+09      1.499400e+10   \n",
            "GE     0.000000e+00  1.811100e+10        4.071100e+10     -1.455700e+10   \n",
            "...             ...           ...                 ...               ...   \n",
            "YRIV   0.000000e+00  3.755251e+06        3.755251e+06     -3.755251e+06   \n",
            "YTEN   4.759000e+06  5.071000e+06        9.830000e+06     -9.274000e+06   \n",
            "ZKIN   1.652633e+06  7.020320e+06        8.672953e+06      9.617636e+06   \n",
            "ZOM    1.031715e+07  4.521349e+06        1.664863e+07     -1.664863e+07   \n",
            "ZYME   5.668400e+07  2.945700e+07        8.614600e+07     -3.312700e+07   \n",
            "\n",
            "       Interest Expense  Earnings before Tax  ...  Receivables growth  \\\n",
            "CMCSA      3.542000e+09         1.511100e+10  ...              0.2570   \n",
            "KMI        1.917000e+09         2.196000e+09  ...              0.0345   \n",
            "INTC      -1.260000e+08         2.331700e+10  ...              0.1989   \n",
            "MU         3.420000e+08         1.430300e+10  ...              0.4573   \n",
            "GE         5.059000e+09        -2.177200e+10  ...             -0.2781   \n",
            "...                 ...                  ...  ...                 ...   \n",
            "YRIV       1.105849e+07        -1.482451e+07  ...              0.0000   \n",
            "YTEN       0.000000e+00        -9.170000e+06  ...              0.3445   \n",
            "ZKIN       1.239170e+06         8.416324e+06  ...              0.1605   \n",
            "ZOM        0.000000e+00        -1.664769e+07  ...              0.8980   \n",
            "ZYME       1.660000e+05        -3.438500e+07  ...             -0.4185   \n",
            "\n",
            "       Inventory Growth  Asset Growth  Book Value per Share Growth  \\\n",
            "CMCSA            0.0000        0.3426                       0.0722   \n",
            "KMI             -0.0920       -0.0024                       0.0076   \n",
            "INTC             0.0387        0.0382                       0.1014   \n",
            "MU               0.1511        0.2275                       0.6395   \n",
            "GE              -0.2892       -0.1575                      -0.4487   \n",
            "...                 ...           ...                          ...   \n",
            "YRIV             0.0000       -0.0508                      -0.1409   \n",
            "YTEN             0.0000       -0.2323                      -0.8602   \n",
            "ZKIN             0.7706        0.2489                       0.4074   \n",
            "ZOM              0.0000        0.1568                      -0.2200   \n",
            "ZYME             0.0000        0.8519                       0.1325   \n",
            "\n",
            "       Debt Growth  R&D Expense Growth  SG&A Expenses Growth  \\\n",
            "CMCSA       0.7309              0.0000                0.1308   \n",
            "KMI        -0.0137              0.0000               -0.1265   \n",
            "INTC       -0.0169              0.0390               -0.0942   \n",
            "MU         -0.5841              0.1738                0.0942   \n",
            "GE         -0.2297              0.0000                0.0308   \n",
            "...            ...                 ...                   ...   \n",
            "YRIV       -0.0152              0.0000               -0.2602   \n",
            "YTEN        0.0000              0.0352               -0.0993   \n",
            "ZKIN       -0.0968              0.2415                0.8987   \n",
            "ZOM         0.0000              2.7499                0.1457   \n",
            "ZYME        0.0000              0.3577                0.5880   \n",
            "\n",
            "                  Sector  2019 PRICE VAR [%]  Class  \n",
            "CMCSA  Consumer Cyclical           32.794573      2  \n",
            "KMI               Energy           40.588068      2  \n",
            "INTC          Technology           30.295514      1  \n",
            "MU            Technology           64.213737      2  \n",
            "GE           Industrials           44.757840      2  \n",
            "...                  ...                 ...    ...  \n",
            "YRIV         Real Estate          -90.962099      0  \n",
            "YTEN     Basic Materials          -77.922077      0  \n",
            "ZKIN     Basic Materials          -17.834400      0  \n",
            "ZOM          Industrials          -73.520000      0  \n",
            "ZYME          Healthcare          209.462222      2  \n",
            "\n",
            "[4392 rows x 224 columns]\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4392, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Replacing zeros with NaNs - 131782 zeros replaced - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 1 - Current shape: (4392, 223)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 229080 NaNs with XGB - NaNImputer(conservative = False, n_feats = 10,            \n",
            "           fix_string_nans = True, verbose = False,                \n",
            "           multiprocessing_load = 1, fill_nans_in_pure_text = True,                    \n",
            "           drop_empty_cols = True, drop_nan_cols_with_constant = True                        \n",
            "           feature_selection = correlation)\n",
            "\n",
            "Impute sequentially on a single core\n",
            "\n",
            "0 NaNs left - COMPLETE\n",
            "Removing 0 columns such that 0 NaNs are left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 88 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 87 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4217, 222)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "############################################################\n",
            "\n",
            "Found 215 intersecting columns!\n",
            "Concatenated DataFrame into shape: (21196, 215)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '/2018 PRICE VAR [%]'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-3793c1c4757e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# generate DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# use full df for cross validation vanilla test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-603d2d8a3772>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# factorize 'Sector' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# avoid encoding issues with feature names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-603d2d8a3772>\u001b[0m in \u001b[0;36mfactorize_col\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msector_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'/{self.year} PRICE VAR [%]'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0msp500_2015_buy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Class\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'/{self.year} PRICE VAR [%]'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0msp500_2015_sell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Class\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         df.loc[(df[f'/{self.year} PRICE VAR [%]'] >= sp500_2015_sell) & \n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '/2018 PRICE VAR [%]'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_vanilla(X_3, y_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "uOvsf0o5ro21",
        "outputId": "feea35c6-0c02-4ec7-cc38-a6fba6758a7b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-9582544dc4f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_vanilla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 4\n",
        "\n",
        "1.   *NaN threshold*\n",
        "2.   *zero threshold*\n",
        "3.   *replace zeros with NaNs*\n",
        "4.   *NaN threshold again*\n",
        "5.   *KNN imputation*\n",
        "6.   *outlier quantile cut*\n",
        "7.   *Isolation Forest outlier handling*"
      ],
      "metadata": {
        "id": "Khb0Dm11rpyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_4 = DataSet(config_dict=config_dict,\n",
        "                    nan_handler = ['threshold'],\n",
        "                    zero_handler = ['threshold', 'replace', 'drop_again'],\n",
        "                    imputation_handler = 'XGB',\n",
        "                    outlier_handler = ['quantile', 'IForest'])\n",
        "\n",
        "# generate DataFrame\n",
        "df_4 = dataset_4.create_dataset()\n",
        "\n",
        "# use full df for cross validation vanilla test\n",
        "X_4, y_4= df_4.drop(columns=['Class']), df_4['Class']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9STn0QbfsV6D",
        "outputId": "f9a33aa5-84a3-40ff-e93b-65c157d0c4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2014 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2014_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (3808, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING NANS ~~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% NaNs - 89 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 60 columns dropped - COMPLETE\n",
            "Replacing zeros with NaNs - 4529 zeros replaced - COMPLETE\n",
            "Dropping columns with more than 8% NaNs - 14 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 164 - Current shape: (3808, 60)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 9864 NaNs with XGB - NaNImputer(conservative = False, n_feats = 10,            \n",
            "           fix_string_nans = True, verbose = False,                \n",
            "           multiprocessing_load = 1, fill_nans_in_pure_text = True,                    \n",
            "           drop_empty_cols = True, drop_nan_cols_with_constant = True                        \n",
            "           feature_selection = correlation)\n",
            "\n",
            "Impute sequentially on a single core\n",
            "\n",
            "169 NaNs left - COMPLETE\n",
            "Removing 1 columns such that 0 NaNs are left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 78 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 75 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (3655, 59)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2015 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2015_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4120, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING NANS ~~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 10% NaNs - 68 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 67 columns dropped - COMPLETE\n",
            "Replacing zeros with NaNs - 5357 zeros replaced - COMPLETE\n",
            "Dropping columns with more than 10% NaNs - 17 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 153 - Current shape: (4120, 71)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 18061 NaNs with XGB - NaNImputer(conservative = False, n_feats = 10,            \n",
            "           fix_string_nans = True, verbose = False,                \n",
            "           multiprocessing_load = 1, fill_nans_in_pure_text = True,                    \n",
            "           drop_empty_cols = True, drop_nan_cols_with_constant = True                        \n",
            "           feature_selection = correlation)\n",
            "\n",
            "Impute sequentially on a single core\n",
            "\n",
            "291 NaNs left - COMPLETE\n",
            "Removing 1 columns such that 0 NaNs are left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 84 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 81 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (3955, 69)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2016 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2016_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4797, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING NANS ~~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 16% NaNs - 97 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 61 columns dropped - COMPLETE\n",
            "Replacing zeros with NaNs - 5318 zeros replaced - COMPLETE\n",
            "Dropping columns with more than 16% NaNs - 17 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 176 - Current shape: (4797, 48)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 29474 NaNs with XGB - NaNImputer(conservative = False, n_feats = 10,            \n",
            "           fix_string_nans = True, verbose = False,                \n",
            "           multiprocessing_load = 1, fill_nans_in_pure_text = True,                    \n",
            "           drop_empty_cols = True, drop_nan_cols_with_constant = True                        \n",
            "           feature_selection = correlation)\n",
            "\n",
            "Impute sequentially on a single core\n",
            "\n",
            "751 NaNs left - COMPLETE\n",
            "Removing 1 columns such that 0 NaNs are left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 96 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 94 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4607, 47)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2017 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2017_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4960, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING NANS ~~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 16% NaNs - 145 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 31 columns dropped - COMPLETE\n",
            "Replacing zeros with NaNs - 3914 zeros replaced - COMPLETE\n",
            "Dropping columns with more than 16% NaNs - 11 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 188 - Current shape: (4960, 36)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 21796 NaNs with XGB - NaNImputer(conservative = False, n_feats = 10,            \n",
            "           fix_string_nans = True, verbose = False,                \n",
            "           multiprocessing_load = 1, fill_nans_in_pure_text = True,                    \n",
            "           drop_empty_cols = True, drop_nan_cols_with_constant = True                        \n",
            "           feature_selection = correlation)\n",
            "\n",
            "Impute sequentially on a single core\n",
            "\n",
            "0 NaNs left - COMPLETE\n",
            "Removing 0 columns such that 0 NaNs are left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 100 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 98 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4762, 36)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ LOADING 2018 ~~~~~~~~~~~~~~~~~~~~~\n",
            "Loading 2018_Financial_Data.csv into a DataFrame - COMPLETE\n",
            "Dropping rows with NaNs only - 0 rows dropped - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Initial DataFrame shape: (4392, 224)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING NANS ~~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% NaNs - 62 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLING ZEROS ~~~~~~~~~~~~~~~~~~~\n",
            "Dropping columns with more than 8% zeros - 70 columns dropped - COMPLETE\n",
            "Replacing zeros with NaNs - 6019 zeros replaced - COMPLETE\n",
            "Dropping columns with more than 8% NaNs - 18 columns dropped - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "------------------------------------------------------------\n",
            "Total amount of columns dropped: 151 - Current shape: (4392, 73)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ IMPUTE NANS ~~~~~~~~~~~~~~~~~~~~~~\n",
            "Imputing 15473 NaNs with XGB - NaNImputer(conservative = False, n_feats = 10,            \n",
            "           fix_string_nans = True, verbose = False,                \n",
            "           multiprocessing_load = 1, fill_nans_in_pure_text = True,                    \n",
            "           drop_empty_cols = True, drop_nan_cols_with_constant = True                        \n",
            "           feature_selection = correlation)\n",
            "\n",
            "Impute sequentially on a single core\n",
            "\n",
            "2650 NaNs left - COMPLETE\n",
            "Removing 11 columns such that 0 NaNs are left - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ HANDLE OUTLIERS ~~~~~~~~~~~~~~~~~~\n",
            "Dropping rows with a price variance outside the 0.01 - 0.99 quantile range - 88 rows dropped - COMPLETE\n",
            "Using Isolation Forest to detect outliers - 87 outliers removed - COMPLETE\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~ SCALING DATA ~~~~~~~~~~~~~~~~~~~~~\n",
            "Scaling data - COMPLETE\n",
            "------------------------------------------------------------\n",
            "Final DataFrame shape: (4217, 61)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "############################################################\n",
            "############################################################\n",
            "\n",
            "Found 28 intersecting columns!\n",
            "Concatenated DataFrame into shape: (21196, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_vanilla(X_4, y_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay4t_2VOsf8p",
        "outputId": "10a23848-efa2-4e07-a689-f37107727df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for ETC: 0.6987644491625383\n",
            "Accuracy for RFC: 0.7015478129854407\n",
            "Accuracy for GBC: 0.6977734714043452\n",
            "Accuracy for LGBMC: 0.702963107621502\n",
            "Accuracy for XGBC: 0.6968300084124504\n",
            "Accuracy for CBC: 0.7039069489511144\n",
            "Accuracy for KNN: 0.6524813946863579\n",
            "Accuracy for SGDC: 0.5021214063480619\n"
          ]
        }
      ]
    }
  ]
}